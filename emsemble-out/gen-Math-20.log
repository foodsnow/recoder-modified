stdout: else_statement -> BlockStatement
using GPU
p
path org.apache.commons.math3.optimization.direct.CMAESOptimizer
repairAndDecode
Position(line=920, column=16)
FOUND IT!
[{'bugid': 'Math-20', 'treeroot': <Searchnode.Node object at 0x7f7aaf2fb290>, 'troot': <Searchnode.Node object at 0x7f7aaf2fb290>, 'oldcode': '            return\n                decode(x);', 'filepath': 'buggy/Math-20/src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java', 'subroot': <Searchnode.Node object at 0x7f7aaf2fb910>, 'vardic': {'repairAndDecode_ter': 'meth0', 'x_ter': 'par0'}, 'typedic': {'x_ter': 'double'}, 'idss': 'Math-20', 'classname': 'org.apache.commons.math3.optimization.direct.CMAESOptimizer', 'precode': '/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the "License"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an "AS IS" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.commons.math3.optimization.direct;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\nimport org.apache.commons.math3.analysis.MultivariateFunction;\nimport org.apache.commons.math3.exception.DimensionMismatchException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.MathIllegalStateException;\nimport org.apache.commons.math3.exception.NotPositiveException;\nimport org.apache.commons.math3.exception.OutOfRangeException;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.linear.Array2DRowRealMatrix;\nimport org.apache.commons.math3.linear.EigenDecomposition;\nimport org.apache.commons.math3.linear.MatrixUtils;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.optimization.ConvergenceChecker;\nimport org.apache.commons.math3.optimization.GoalType;\nimport org.apache.commons.math3.optimization.MultivariateOptimizer;\nimport org.apache.commons.math3.optimization.PointValuePair;\nimport org.apache.commons.math3.optimization.SimpleValueChecker;\nimport org.apache.commons.math3.random.MersenneTwister;\nimport org.apache.commons.math3.random.RandomGenerator;\nimport org.apache.commons.math3.util.MathArrays;\n\n/**\n * <p>An implementation of the active Covariance Matrix Adaptation Evolution Strategy (CMA-ES)\n * for non-linear, non-convex, non-smooth, global function minimization.\n * The CMA-Evolution Strategy (CMA-ES) is a reliable stochastic optimization method\n * which should be applied if derivative-based methods, e.g. quasi-Newton BFGS or\n * conjugate gradient, fail due to a rugged search landscape (e.g. noise, local\n * optima, outlier, etc.) of the objective function. Like a\n * quasi-Newton method, the CMA-ES learns and applies a variable metric\n * on the underlying search space. Unlike a quasi-Newton method, the\n * CMA-ES neither estimates nor uses gradients, making it considerably more\n * reliable in terms of finding a good, or even close to optimal, solution.</p>\n *\n * <p>In general, on smooth objective functions the CMA-ES is roughly ten times\n * slower than BFGS (counting objective function evaluations, no gradients provided).\n * For up to <math>N=10</math> variables also the derivative-free simplex\n * direct search method (Nelder and Mead) can be faster, but it is\n * far less reliable than CMA-ES.</p>\n *\n * <p>The CMA-ES is particularly well suited for non-separable\n * and/or badly conditioned problems. To observe the advantage of CMA compared\n * to a conventional evolution strategy, it will usually take about\n * <math>30 N</math> function evaluations. On difficult problems the complete\n * optimization (a single run) is expected to take <em>roughly</em> between\n * <math>30 N</math> and <math>300 N<sup>2</sup></math>\n * function evaluations.</p>\n *\n * <p>This implementation is translated and adapted from the Matlab version\n * of the CMA-ES algorithm as implemented in module {@code cmaes.m} version 3.51.</p>\n *\n * For more information, please refer to the following links:\n * <ul>\n *  <li><a href="http://www.lri.fr/~hansen/cmaes.m">Matlab code</a></li>\n *  <li><a href="http://www.lri.fr/~hansen/cmaesintro.html">Introduction to CMA-ES</a></li>\n *  <li><a href="http://en.wikipedia.org/wiki/CMA-ES">Wikipedia</a></li>\n * </ul>\n *\n * @version $Id$\n * @since 3.0\n */\n\npublic class CMAESOptimizer\n    extends BaseAbstractMultivariateSimpleBoundsOptimizer<MultivariateFunction>\n    implements MultivariateOptimizer {\n    /** Default value for {@link #checkFeasableCount}: {@value}. */\n    public static final int DEFAULT_CHECKFEASABLECOUNT = 0;\n    /** Default value for {@link #stopFitness}: {@value}. */\n    public static final double DEFAULT_STOPFITNESS = 0;\n    /** Default value for {@link #isActiveCMA}: {@value}. */\n    public static final boolean DEFAULT_ISACTIVECMA = true;\n    /** Default value for {@link #maxIterations}: {@value}. */\n    public static final int DEFAULT_MAXITERATIONS = 30000;\n    /** Default value for {@link #diagonalOnly}: {@value}. */\n    public static final int DEFAULT_DIAGONALONLY = 0;\n    /** Default value for {@link #random}. */\n    public static final RandomGenerator DEFAULT_RANDOMGENERATOR = new MersenneTwister();\n\n    // global search parameters\n    /**\n     * Population size, offspring number. The primary strategy parameter to play\n     * with, which can be increased from its default value. Increasing the\n     * population size improves global search properties in exchange to speed.\n     * Speed decreases, as a rule, at most linearly with increasing population\n     * size. It is advisable to begin with the default small population size.\n     */\n    private int lambda; // population size\n    /**\n     * Covariance update mechanism, default is active CMA. isActiveCMA = true\n     * turns on "active CMA" with a negative update of the covariance matrix and\n     * checks for positive definiteness. OPTS.CMA.active = 2 does not check for\n     * pos. def. and is numerically faster. Active CMA usually speeds up the\n     * adaptation.\n     */\n    private boolean isActiveCMA;\n    /**\n     * Determines how often a new random offspring is generated in case it is\n     * not feasible / beyond the defined limits, default is 0. Only relevant if\n     * boundaries != null.\n     */\n    private int checkFeasableCount;\n    /**\n     * Lower and upper boundaries of the objective variables. boundaries == null\n     * means no boundaries.\n     */\n    private double[][] boundaries;\n    /**\n     * Individual sigma values - initial search volume. inputSigma determines\n     * the initial coordinate wise standard deviations for the search. Setting\n     * SIGMA one third of the initial search region is appropriate.\n     */\n    private double[] inputSigma;\n    /** Number of objective variables/problem dimension */\n    private int dimension;\n    /**\n     * Defines the number of initial iterations, where the covariance matrix\n     * remains diagonal and the algorithm has internally linear time complexity.\n     * diagonalOnly = 1 means keeping the covariance matrix always diagonal and\n     * this setting also exhibits linear space complexity. This can be\n     * particularly useful for dimension > 100.\n     * @see <a href="http://hal.archives-ouvertes.fr/inria-00287367/en">A Simple Modification in CMA-ES</a>\n     */\n    private int diagonalOnly = 0;\n    /** Number of objective variables/problem dimension */\n    private boolean isMinimize = true;\n    /** Indicates whether statistic data is collected. */\n    private boolean generateStatistics = false;\n\n    // termination criteria\n    /** Maximal number of iterations allowed. */\n    private int maxIterations;\n    /** Limit for fitness value. */\n    private double stopFitness;\n    /** Stop if x-changes larger stopTolUpX. */\n    private double stopTolUpX;\n    /** Stop if x-change smaller stopTolX. */\n    private double stopTolX;\n    /** Stop if fun-changes smaller stopTolFun. */\n    private double stopTolFun;\n    /** Stop if back fun-changes smaller stopTolHistFun. */\n    private double stopTolHistFun;\n\n    // selection strategy parameters\n    /** Number of parents/points for recombination. */\n    private int mu; //\n    /** log(mu + 0.5), stored for efficiency. */\n    private double logMu2;\n    /** Array for weighted recombination. */\n    private RealMatrix weights;\n    /** Variance-effectiveness of sum w_i x_i. */\n    private double mueff; //\n\n    // dynamic strategy parameters and constants\n    /** Overall standard deviation - search volume. */\n    private double sigma;\n    /** Cumulation constant. */\n    private double cc;\n    /** Cumulation constant for step-size. */\n    private double cs;\n    /** Damping for step-size. */\n    private double damps;\n    /** Learning rate for rank-one update. */\n    private double ccov1;\n    /** Learning rate for rank-mu update\' */\n    private double ccovmu;\n    /** Expectation of ||N(0,I)|| == norm(randn(N,1)). */\n    private double chiN;\n    /** Learning rate for rank-one update - diagonalOnly */\n    private double ccov1Sep;\n    /** Learning rate for rank-mu update - diagonalOnly */\n    private double ccovmuSep;\n\n    // CMA internal values - updated each generation\n    /** Objective variables. */\n    private RealMatrix xmean;\n    /** Evolution path. */\n    private RealMatrix pc;\n    /** Evolution path for sigma. */\n    private RealMatrix ps;\n    /** Norm of ps, stored for efficiency. */\n    private double normps;\n    /** Coordinate system. */\n    private RealMatrix B;\n    /** Scaling. */\n    private RealMatrix D;\n    /** B*D, stored for efficiency. */\n    private RealMatrix BD;\n    /** Diagonal of sqrt(D), stored for efficiency. */\n    private RealMatrix diagD;\n    /** Covariance matrix. */\n    private RealMatrix C;\n    /** Diagonal of C, used for diagonalOnly. */\n    private RealMatrix diagC;\n    /** Number of iterations already performed. */\n    private int iterations;\n\n    /** History queue of best values. */\n    private double[] fitnessHistory;\n    /** Size of history queue of best values. */\n    private int historySize;\n\n    /** Random generator. */\n    private RandomGenerator random;\n\n    /** History of sigma values. */\n    private List<Double> statisticsSigmaHistory = new ArrayList<Double>();\n    /** History of mean matrix. */\n    private List<RealMatrix> statisticsMeanHistory = new ArrayList<RealMatrix>();\n    /** History of fitness values. */\n    private List<Double> statisticsFitnessHistory = new ArrayList<Double>();\n    /** History of D matrix. */\n    private List<RealMatrix> statisticsDHistory = new ArrayList<RealMatrix>();\n\n    /**\n     * Default constructor, uses default parameters\n     */\n    public CMAESOptimizer() {\n        this(0);\n    }\n\n    /**\n     * @param lambda Population size.\n     */\n    public CMAESOptimizer(int lambda) {\n        this(lambda, null, DEFAULT_MAXITERATIONS, DEFAULT_STOPFITNESS,\n             DEFAULT_ISACTIVECMA, DEFAULT_DIAGONALONLY,\n             DEFAULT_CHECKFEASABLECOUNT, DEFAULT_RANDOMGENERATOR, false);\n    }\n\n    /**\n     * @param lambda Population size.\n     * @param inputSigma Initial search volume; sigma of offspring objective variables.\n     */\n    public CMAESOptimizer(int lambda, double[] inputSigma) {\n        this(lambda, inputSigma, DEFAULT_MAXITERATIONS, DEFAULT_STOPFITNESS,\n             DEFAULT_ISACTIVECMA, DEFAULT_DIAGONALONLY,\n             DEFAULT_CHECKFEASABLECOUNT, DEFAULT_RANDOMGENERATOR, false);\n    }\n\n    /**\n     * @param lambda Population size.\n     * @param inputSigma Initial search volume; sigma of offspring objective variables.\n     * @param maxIterations Maximal number of iterations.\n     * @param stopFitness Whether to stop if objective function value is smaller than\n     * {@code stopFitness}.\n     * @param isActiveCMA Chooses the covariance matrix update method.\n     * @param diagonalOnly Number of initial iterations, where the covariance matrix\n     * remains diagonal.\n     * @param checkFeasableCount Determines how often new random objective variables are\n     * generated in case they are out of bounds.\n     * @param random Random generator.\n     * @param generateStatistics Whether statistic data is collected.\n     * @deprecated See {@link SimpleValueChecker#SimpleValueChecker()}\n     */\n    @Deprecated\n    public CMAESOptimizer(int lambda, double[] inputSigma,\n                          int maxIterations, double stopFitness,\n                          boolean isActiveCMA, int diagonalOnly, int checkFeasableCount,\n                          RandomGenerator random, boolean generateStatistics) {\n        this(lambda, inputSigma, maxIterations, stopFitness, isActiveCMA,\n             diagonalOnly, checkFeasableCount, random, generateStatistics,\n             new SimpleValueChecker());\n    }\n\n    /**\n     * @param lambda Population size.\n     * @param inputSigma Initial search volume; sigma of offspring objective variables.\n     * @param maxIterations Maximal number of iterations.\n     * @param stopFitness Whether to stop if objective function value is smaller than\n     * {@code stopFitness}.\n     * @param isActiveCMA Chooses the covariance matrix update method.\n     * @param diagonalOnly Number of initial iterations, where the covariance matrix\n     * remains diagonal.\n     * @param checkFeasableCount Determines how often new random objective variables are\n     * generated in case they are out of bounds.\n     * @param random Random generator.\n     * @param generateStatistics Whether statistic data is collected.\n     * @param checker Convergence checker.\n     */\n    public CMAESOptimizer(int lambda, double[] inputSigma,\n                          int maxIterations, double stopFitness,\n                          boolean isActiveCMA, int diagonalOnly, int checkFeasableCount,\n                          RandomGenerator random, boolean generateStatistics,\n                          ConvergenceChecker<PointValuePair> checker) {\n        super(checker);\n        this.lambda = lambda;\n        this.inputSigma = inputSigma == null ? null : (double[]) inputSigma.clone();\n        this.maxIterations = maxIterations;\n        this.stopFitness = stopFitness;\n        this.isActiveCMA = isActiveCMA;\n        this.diagonalOnly = diagonalOnly;\n        this.checkFeasableCount = checkFeasableCount;\n        this.random = random;\n        this.generateStatistics = generateStatistics;\n    }\n\n    /**\n     * @return History of sigma values.\n     */\n    public List<Double> getStatisticsSigmaHistory() {\n        return statisticsSigmaHistory;\n    }\n\n    /**\n     * @return History of mean matrix.\n     */\n    public List<RealMatrix> getStatisticsMeanHistory() {\n        return statisticsMeanHistory;\n    }\n\n    /**\n     * @return History of fitness values.\n     */\n    public List<Double> getStatisticsFitnessHistory() {\n        return statisticsFitnessHistory;\n    }\n\n    /**\n     * @return History of D matrix.\n     */\n    public List<RealMatrix> getStatisticsDHistory() {\n        return statisticsDHistory;\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    protected PointValuePair doOptimize() {\n        checkParameters();\n         // -------------------- Initialization --------------------------------\n        isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n        final FitnessFunction fitfun = new FitnessFunction();\n        final double[] guess = fitfun.encode(getStartPoint());\n        // number of objective variables/problem dimension\n        dimension = guess.length;\n        initializeCMA(guess);\n        iterations = 0;\n        double bestValue = fitfun.value(guess);\n        push(fitnessHistory, bestValue);\n        PointValuePair optimum = new PointValuePair(getStartPoint(),\n                isMinimize ? bestValue : -bestValue);\n        PointValuePair lastResult = null;\n\n        // -------------------- Generation Loop --------------------------------\n\n        generationLoop:\n            for (iterations = 1; iterations <= maxIterations; iterations++) {\n                // Generate and evaluate lambda offspring\n                RealMatrix arz = randn1(dimension, lambda);\n                RealMatrix arx = zeros(dimension, lambda);\n                double[] fitness = new double[lambda];\n                // generate random offspring\n                for (int k = 0; k < lambda; k++) {\n                    RealMatrix arxk = null;\n                    for (int i = 0; i < checkFeasableCount+1; i++) {\n                        if (diagonalOnly <= 0) {\n                            arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n                                    .scalarMultiply(sigma)); // m + sig * Normal(0,C)\n                        } else {\n                            arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n                                    .scalarMultiply(sigma));\n                        }\n                        if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {\n                            break;\n                        }\n                        // regenerate random arguments for row\n                        arz.setColumn(k, randn(dimension));\n                    }\n                    copyColumn(arxk, 0, arx, k);\n                    try {\n                        fitness[k] = fitfun.value(arx.getColumn(k)); // compute fitness\n                    } catch (TooManyEvaluationsException e) {\n                        break generationLoop;\n                    }\n                }\n                // Sort by fitness and compute weighted mean into xmean\n                int[] arindex = sortedIndices(fitness);\n                // Calculate new xmean, this is selection and recombination\n                RealMatrix xold = xmean; // for speed up of Eq. (2) and (3)\n                RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n                xmean = bestArx.multiply(weights);\n                RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n                RealMatrix zmean = bestArz.multiply(weights);\n                boolean hsig = updateEvolutionPaths(zmean, xold);\n                if (diagonalOnly <= 0) {\n                    updateCovariance(hsig, bestArx, arz, arindex, xold);\n                } else {\n                    updateCovarianceDiagonalOnly(hsig, bestArz, xold);\n                }\n                // Adapt step size sigma - Eq. (5)\n                sigma *= Math.exp(Math.min(1.0,(normps/chiN - 1.)*cs/damps));\n                double bestFitness = fitness[arindex[0]];\n                double worstFitness = fitness[arindex[arindex.length-1]];\n                if (bestValue > bestFitness) {\n                    bestValue = bestFitness;\n                    lastResult = optimum;\n                    optimum = new PointValuePair(\n                            fitfun.repairAndDecode(bestArx.getColumn(0)),\n                            isMinimize ? bestFitness : -bestFitness);\n                    if (getConvergenceChecker() != null && lastResult != null) {\n                        if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n                            break generationLoop;\n                        }\n                    }\n                }\n                // handle termination criteria\n                // Break, if fitness is good enough\n                if (stopFitness != 0) { // only if stopFitness is defined\n                    if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n                        break generationLoop;\n                    }\n                }\n                double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n                double[] pcCol = pc.getColumn(0);\n                for (int i = 0; i < dimension; i++) {\n                    if (sigma*(Math.max(Math.abs(pcCol[i]), sqrtDiagC[i])) > stopTolX) {\n                        break;\n                    }\n                    if (i >= dimension-1) {\n                        break generationLoop;\n                    }\n                }\n                for (int i = 0; i < dimension; i++) {\n                    if (sigma*sqrtDiagC[i] > stopTolUpX) {\n                        break generationLoop;\n                    }\n                }\n                double historyBest = min(fitnessHistory);\n                double historyWorst = max(fitnessHistory);\n                if (iterations > 2 && Math.max(historyWorst, worstFitness) -\n                        Math.min(historyBest, bestFitness) < stopTolFun) {\n                    break generationLoop;\n                }\n                if (iterations > fitnessHistory.length &&\n                        historyWorst-historyBest < stopTolHistFun) {\n                    break generationLoop;\n                }\n                // condition number of the covariance matrix exceeds 1e14\n                if (max(diagD)/min(diagD) > 1e7) {\n                    break generationLoop;\n                }\n                // user defined termination\n                if (getConvergenceChecker() != null) {\n                    PointValuePair current =\n                        new PointValuePair(bestArx.getColumn(0),\n                                isMinimize ? bestFitness : -bestFitness);\n                    if (lastResult != null &&\n                        getConvergenceChecker().converged(iterations, current, lastResult)) {\n                        break generationLoop;\n                    }\n                    lastResult = current;\n                }\n                // Adjust step size in case of equal function values (flat fitness)\n                if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n                    sigma = sigma * Math.exp(0.2+cs/damps);\n                }\n                if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n                        Math.min(historyBest, bestFitness) == 0) {\n                    sigma = sigma * Math.exp(0.2+cs/damps);\n                }\n                // store best in history\n                push(fitnessHistory,bestFitness);\n                fitfun.setValueRange(worstFitness-bestFitness);\n                if (generateStatistics) {\n                    statisticsSigmaHistory.add(sigma);\n                    statisticsFitnessHistory.add(bestFitness);\n                    statisticsMeanHistory.add(xmean.transpose());\n                    statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n                }\n            }\n        return optimum;\n    }\n\n    /**\n     * Checks dimensions and values of boundaries and inputSigma if defined.\n     */\n    private void checkParameters() {\n        final double[] init = getStartPoint();\n        final double[] lB = getLowerBound();\n        final double[] uB = getUpperBound();\n\n        // Checks whether there is at least one finite bound value.\n        boolean hasFiniteBounds = false;\n        for (int i = 0; i < lB.length; i++) {\n            if (!Double.isInfinite(lB[i]) ||\n                !Double.isInfinite(uB[i])) {\n                hasFiniteBounds = true;\n                break;\n            }\n        }\n        // Checks whether there is at least one infinite bound value.\n        boolean hasInfiniteBounds = false;\n        if (hasFiniteBounds) {\n            for (int i = 0; i < lB.length; i++) {\n                if (Double.isInfinite(lB[i]) ||\n                    Double.isInfinite(uB[i])) {\n                    hasInfiniteBounds = true;\n                    break;\n                }\n            }\n\n            if (hasInfiniteBounds) {\n                // If there is at least one finite bound, none can be infinite,\n                // because mixed cases are not supported by the current code.\n                throw new MathUnsupportedOperationException();\n            } else {\n                // Convert API to internal handling of boundaries.\n                boundaries = new double[2][];\n                boundaries[0] = lB;\n                boundaries[1] = uB;\n            }\n        } else {\n            // Convert API to internal handling of boundaries.\n            boundaries = null;\n        }\n\n        if (inputSigma != null) {\n            if (inputSigma.length != init.length) {\n                throw new DimensionMismatchException(inputSigma.length, init.length);\n            }\n            for (int i = 0; i < init.length; i++) {\n                if (inputSigma[i] < 0) {\n                    throw new NotPositiveException(inputSigma[i]);\n                }\n                if (boundaries != null) {\n                    if (inputSigma[i] > boundaries[1][i] - boundaries[0][i]) {\n                        throw new OutOfRangeException(inputSigma[i], 0, boundaries[1][i] - boundaries[0][i]);\n                    }\n                }\n            }\n        }\n    }\n\n    /**\n     * Initialization of the dynamic search parameters\n     *\n     * @param guess Initial guess for the arguments of the fitness function.\n     */\n    private void initializeCMA(double[] guess) {\n        if (lambda <= 0) {\n            lambda = 4 + (int) (3. * Math.log(dimension));\n        }\n        // initialize sigma\n        double[][] sigmaArray = new double[guess.length][1];\n        for (int i = 0; i < guess.length; i++) {\n            final double range =  (boundaries == null) ? 1.0 : boundaries[1][i] - boundaries[0][i];\n            sigmaArray[i][0]   = ((inputSigma == null) ? 0.3 : inputSigma[i]) / range;\n        }\n        RealMatrix insigma = new Array2DRowRealMatrix(sigmaArray, false);\n        sigma = max(insigma); // overall standard deviation\n\n        // initialize termination criteria\n        stopTolUpX = 1e3 * max(insigma);\n        stopTolX = 1e-11 * max(insigma);\n        stopTolFun = 1e-12;\n        stopTolHistFun = 1e-13;\n\n        // initialize selection strategy parameters\n        mu = lambda / 2; // number of parents/points for recombination\n        logMu2 = Math.log(mu + 0.5);\n        weights = log(sequence(1, mu, 1)).scalarMultiply(-1.).scalarAdd(logMu2);\n        double sumw = 0;\n        double sumwq = 0;\n        for (int i = 0; i < mu; i++) {\n            double w = weights.getEntry(i, 0);\n            sumw += w;\n            sumwq += w * w;\n        }\n        weights = weights.scalarMultiply(1. / sumw);\n        mueff = sumw * sumw / sumwq; // variance-effectiveness of sum w_i x_i\n\n        // initialize dynamic strategy parameters and constants\n        cc = (4. + mueff / dimension) /\n                (dimension + 4. + 2. * mueff / dimension);\n        cs = (mueff + 2.) / (dimension + mueff + 3.);\n        damps = (1. + 2. * Math.max(0, Math.sqrt((mueff - 1.) /\n                (dimension + 1.)) - 1.)) *\n                Math.max(0.3, 1. - dimension /\n                        (1e-6 + Math.min(maxIterations, getMaxEvaluations() /\n                                lambda))) + cs; // minor increment\n        ccov1 = 2. / ((dimension + 1.3) * (dimension + 1.3) + mueff);\n        ccovmu = Math.min(1 - ccov1, 2. * (mueff - 2. + 1. / mueff) /\n                ((dimension + 2.) * (dimension + 2.) + mueff));\n        ccov1Sep = Math.min(1, ccov1 * (dimension + 1.5) / 3.);\n        ccovmuSep = Math.min(1 - ccov1, ccovmu * (dimension + 1.5) / 3.);\n        chiN = Math.sqrt(dimension) *\n                (1. - 1. / (4. * dimension) + 1 / (21. * dimension * dimension));\n        // intialize CMA internal values - updated each generation\n        xmean = MatrixUtils.createColumnRealMatrix(guess); // objective\n                                                           // variables\n        diagD = insigma.scalarMultiply(1. / sigma);\n        diagC = square(diagD);\n        pc = zeros(dimension, 1); // evolution paths for C and sigma\n        ps = zeros(dimension, 1); // B defines the coordinate system\n        normps = ps.getFrobeniusNorm();\n\n        B = eye(dimension, dimension);\n        D = ones(dimension, 1); // diagonal D defines the scaling\n        BD = times(B, repmat(diagD.transpose(), dimension, 1));\n        C = B.multiply(diag(square(D)).multiply(B.transpose())); // covariance\n        historySize = 10 + (int) (3. * 10. * dimension / lambda);\n        fitnessHistory = new double[historySize]; // history of fitness values\n        for (int i = 0; i < historySize; i++) {\n            fitnessHistory[i] = Double.MAX_VALUE;\n        }\n    }\n\n    /**\n     * Update of the evolution paths ps and pc.\n     *\n     * @param zmean Weighted row matrix of the gaussian random numbers generating\n     * the current offspring.\n     * @param xold xmean matrix of the previous generation.\n     * @return hsig flag indicating a small correction.\n     */\n    private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold) {\n        ps = ps.scalarMultiply(1. - cs).add(\n                B.multiply(zmean).scalarMultiply(\n                        Math.sqrt(cs * (2. - cs) * mueff)));\n        normps = ps.getFrobeniusNorm();\n        boolean hsig = normps /\n            Math.sqrt(1. - Math.pow(1. - cs, 2. * iterations)) /\n                chiN < 1.4 + 2. / (dimension + 1.);\n        pc = pc.scalarMultiply(1. - cc);\n        if (hsig) {\n            pc = pc.add(xmean.subtract(xold).scalarMultiply(\n                    Math.sqrt(cc * (2. - cc) * mueff) / sigma));\n        }\n        return hsig;\n    }\n\n    /**\n     * Update of the covariance matrix C for diagonalOnly > 0\n     *\n     * @param hsig Flag indicating a small correction.\n     * @param bestArz Fitness-sorted matrix of the gaussian random values of the\n     * current offspring.\n     * @param xold xmean matrix of the previous generation.\n     */\n    private void updateCovarianceDiagonalOnly(boolean hsig,\n                                              final RealMatrix bestArz,\n                                              final RealMatrix xold) {\n        // minor correction if hsig==false\n        double oldFac = hsig ? 0 : ccov1Sep * cc * (2. - cc);\n        oldFac += 1. - ccov1Sep - ccovmuSep;\n        diagC = diagC.scalarMultiply(oldFac) // regard old matrix\n                // plus rank one update\n                .add(square(pc).scalarMultiply(ccov1Sep))\n                // plus rank mu update\n                .add((times(diagC, square(bestArz).multiply(weights)))\n                        .scalarMultiply(ccovmuSep));\n        diagD = sqrt(diagC); // replaces eig(C)\n        if (diagonalOnly > 1 && iterations > diagonalOnly) {\n            // full covariance matrix from now on\n            diagonalOnly = 0;\n            B = eye(dimension, dimension);\n            BD = diag(diagD);\n            C = diag(diagC);\n        }\n    }\n\n    /**\n     * Update of the covariance matrix C.\n     *\n     * @param hsig Flag indicating a small correction.\n     * @param bestArx Fitness-sorted matrix of the argument vectors producing the\n     * current offspring.\n     * @param arz Unsorted matrix containing the gaussian random values of the\n     * current offspring.\n     * @param arindex Indices indicating the fitness-order of the current offspring.\n     * @param xold xmean matrix of the previous generation.\n     */\n    private void updateCovariance(boolean hsig, final RealMatrix bestArx,\n            final RealMatrix arz, final int[] arindex, final RealMatrix xold) {\n        double negccov = 0;\n        if (ccov1 + ccovmu > 0) {\n            RealMatrix arpos = bestArx.subtract(repmat(xold, 1, mu))\n                    .scalarMultiply(1. / sigma); // mu difference vectors\n            RealMatrix roneu = pc.multiply(pc.transpose())\n                    .scalarMultiply(ccov1); // rank one update\n            // minor correction if hsig==false\n            double oldFac = hsig ? 0 : ccov1 * cc * (2. - cc);\n            oldFac += 1. - ccov1 - ccovmu;\n            if (isActiveCMA) {\n                // Adapt covariance matrix C active CMA\n                negccov = (1. - ccovmu) * 0.25 * mueff /\n                (Math.pow(dimension + 2., 1.5) + 2. * mueff);\n                double negminresidualvariance = 0.66;\n                // keep at least 0.66 in all directions, small popsize are most\n                // critical\n                double negalphaold = 0.5; // where to make up for the variance\n                                          // loss,\n                // prepare vectors, compute negative updating matrix Cneg\n                int[] arReverseIndex = reverse(arindex);\n                RealMatrix arzneg\n                    = selectColumns(arz, MathArrays.copyOf(arReverseIndex, mu));\n                RealMatrix arnorms = sqrt(sumRows(square(arzneg)));\n                int[] idxnorms = sortedIndices(arnorms.getRow(0));\n                RealMatrix arnormsSorted = selectColumns(arnorms, idxnorms);\n                int[] idxReverse = reverse(idxnorms);\n                RealMatrix arnormsReverse = selectColumns(arnorms, idxReverse);\n                arnorms = divide(arnormsReverse, arnormsSorted);\n                int[] idxInv = inverse(idxnorms);\n                RealMatrix arnormsInv = selectColumns(arnorms, idxInv);\n                // check and set learning rate negccov\n                double negcovMax = (1. - negminresidualvariance) /\n                        square(arnormsInv).multiply(weights).getEntry(0, 0);\n                if (negccov > negcovMax) {\n                    negccov = negcovMax;\n                }\n                arzneg = times(arzneg, repmat(arnormsInv, dimension, 1));\n                RealMatrix artmp = BD.multiply(arzneg);\n                RealMatrix Cneg = artmp.multiply(diag(weights)).multiply(\n                        artmp.transpose());\n                oldFac += negalphaold * negccov;\n                C = C.scalarMultiply(oldFac)\n                        // regard old matrix\n                        .add(roneu)\n                        // plus rank one update\n                        .add(arpos.scalarMultiply(\n                                // plus rank mu update\n                                ccovmu + (1. - negalphaold) * negccov)\n                                .multiply(\n                                        times(repmat(weights, 1, dimension),\n                                                arpos.transpose())))\n                        .subtract(Cneg.scalarMultiply(negccov));\n            } else {\n                // Adapt covariance matrix C - nonactive\n                C = C.scalarMultiply(oldFac) // regard old matrix\n                        .add(roneu)\n                        // plus rank one update\n                        .add(arpos.scalarMultiply(ccovmu) // plus rank mu update\n                                .multiply(\n                                        times(repmat(weights, 1, dimension),\n                                                arpos.transpose())));\n            }\n        }\n        updateBD(negccov);\n    }\n\n    /**\n     * Update B and D from C.\n     *\n     * @param negccov Negative covariance factor.\n     */\n    private void updateBD(double negccov) {\n        if (ccov1 + ccovmu + negccov > 0 &&\n                (iterations % 1. / (ccov1 + ccovmu + negccov) / dimension / 10.) < 1.) {\n            // to achieve O(N^2)\n            C = triu(C, 0).add(triu(C, 1).transpose());\n            // enforce symmetry to prevent complex numbers\n            EigenDecomposition eig = new EigenDecomposition(C);\n            B = eig.getV(); // eigen decomposition, B==normalized eigenvectors\n            D = eig.getD();\n            diagD = diag(D);\n            if (min(diagD) <= 0) {\n                for (int i = 0; i < dimension; i++) {\n                    if (diagD.getEntry(i, 0) < 0) {\n                        diagD.setEntry(i, 0, 0.);\n                    }\n                }\n                double tfac = max(diagD) / 1e14;\n                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n            }\n            if (max(diagD) > 1e14 * min(diagD)) {\n                double tfac = max(diagD) / 1e14 - min(diagD);\n                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n            }\n            diagC = diag(C);\n            diagD = sqrt(diagD); // D contains standard deviations now\n            BD = times(B, repmat(diagD.transpose(), dimension, 1)); // O(n^2)\n        }\n    }\n\n    /**\n     * Pushes the current best fitness value in a history queue.\n     *\n     * @param vals History queue.\n     * @param val Current best fitness value.\n     */\n    private static void push(double[] vals, double val) {\n        for (int i = vals.length-1; i > 0; i--) {\n            vals[i] = vals[i-1];\n        }\n        vals[0] = val;\n    }\n\n    /**\n     * Sorts fitness values.\n     *\n     * @param doubles Array of values to be sorted.\n     * @return a sorted array of indices pointing into doubles.\n     */\n    private int[] sortedIndices(final double[] doubles) {\n        DoubleIndex[] dis = new DoubleIndex[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            dis[i] = new DoubleIndex(doubles[i], i);\n        }\n        Arrays.sort(dis);\n        int[] indices = new int[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            indices[i] = dis[i].index;\n        }\n        return indices;\n    }\n\n    /**\n     * Used to sort fitness values. Sorting is always in lower value first\n     * order.\n     */\n    private static class DoubleIndex implements Comparable<DoubleIndex> {\n        /** Value to compare. */\n        private double value;\n        /** Index into sorted array. */\n        private int index;\n\n        /**\n         * @param value Value to compare.\n         * @param index Index into sorted array.\n         */\n        DoubleIndex(double value, int index) {\n            this.value = value;\n            this.index = index;\n        }\n\n        /** {@inheritDoc} */\n        public int compareTo(DoubleIndex o) {\n            return Double.compare(value, o.value);\n        }\n\n        /** {@inheritDoc} */\n        @Override\n        public boolean equals(Object other) {\n\n            if (this == other) {\n                return true;\n            }\n\n            if (other instanceof DoubleIndex) {\n                return Double.compare(value, ((DoubleIndex) other).value) == 0;\n            }\n\n            return false;\n\n        }\n\n        /** {@inheritDoc} */\n        @Override\n        public int hashCode() {\n            long bits = Double.doubleToLongBits(value);\n            return (int) ((1438542 ^ (bits >>> 32) ^ bits) & 0xffffffff);\n        }\n\n    }\n\n    /**\n     * Normalizes fitness values to the range [0,1]. Adds a penalty to the\n     * fitness value if out of range. The penalty is adjusted by calling\n     * setValueRange().\n     */\n    private class FitnessFunction {\n        /** Determines the penalty for boundary violations */\n        private double valueRange;\n        /**\n         * Flag indicating whether the objective variables are forced into their\n         * bounds if defined\n         */\n        private boolean isRepairMode;\n\n        /** Simple constructor.\n         */\n        public FitnessFunction() {\n            valueRange = 1.0;\n            isRepairMode = true;\n        }\n\n        /**\n         * @param x Original objective variables.\n         * @return the normalized objective variables.\n         */\n        public double[] encode(final double[] x) {\n            if (boundaries == null) {\n                return x;\n            }\n            double[] res = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                double diff = boundaries[1][i] - boundaries[0][i];\n                res[i] = (x[i] - boundaries[0][i]) / diff;\n            }\n            return res;\n        }\n\n        /**\n         * @param x Normalized objective variables.\n         * @return the original objective variables, possibly repaired.\n         */\n        public double[] repairAndDecode(final double[] x) {', 'aftercode': '        }\n\n        /**\n         * @param x Normalized objective variables.\n         * @return the original objective variables.\n         */\n        public double[] decode(final double[] x) {\n            if (boundaries == null) {\n                return x;\n            }\n            double[] res = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                double diff = boundaries[1][i] - boundaries[0][i];\n                res[i] = diff * x[i] + boundaries[0][i];\n            }\n            return res;\n        }\n\n        /**\n         * @param point Normalized objective variables.\n         * @return the objective value + penalty for violated bounds.\n         */\n        public double value(final double[] point) {\n            double value;\n            if (boundaries != null && isRepairMode) {\n                double[] repaired = repair(point);\n                value = CMAESOptimizer.this\n                        .computeObjectiveValue(decode(repaired)) +\n                        penalty(point, repaired);\n            } else {\n                value = CMAESOptimizer.this\n                        .computeObjectiveValue(decode(point));\n            }\n            return isMinimize ? value : -value;\n        }\n\n        /**\n         * @param x Normalized objective variables.\n         * @return {@code true} if in bounds.\n         */\n        public boolean isFeasible(final double[] x) {\n            if (boundaries == null) {\n                return true;\n            }\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < 0) {\n                    return false;\n                }\n                if (x[i] > 1.0) {\n                    return false;\n                }\n            }\n            return true;\n        }\n\n        /**\n         * @param valueRange Adjusts the penalty computation.\n         */\n        public void setValueRange(double valueRange) {\n            this.valueRange = valueRange;\n        }\n\n        /**\n         * @param x Normalized objective variables.\n         * @return the repaired objective variables - all in bounds.\n         */\n        private double[] repair(final double[] x) {\n            double[] repaired = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < 0) {\n                    repaired[i] = 0;\n                } else if (x[i] > 1.0) {\n                    repaired[i] = 1.0;\n                } else {\n                    repaired[i] = x[i];\n                }\n            }\n            return repaired;\n        }\n\n        /**\n         * @param x Normalized objective variables.\n         * @param repaired Repaired objective variables.\n         * @return Penalty value according to the violation of the bounds.\n         */\n        private double penalty(final double[] x, final double[] repaired) {\n            double penalty = 0;\n            for (int i = 0; i < x.length; i++) {\n                double diff = Math.abs(x[i] - repaired[i]);\n                penalty += diff * valueRange;\n            }\n            return isMinimize ? penalty : -penalty;\n        }\n    }\n\n    // -----Matrix utility functions similar to the Matlab build in functions------\n\n    /**\n     * @param m Input matrix\n     * @return Matrix representing the element-wise logarithm of m.\n     */\n    private static RealMatrix log(final RealMatrix m) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.log(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m\n     *            Input matrix\n     * @return Matrix representing the element-wise square root of m.\n     */\n    private static RealMatrix sqrt(final RealMatrix m) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.sqrt(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix\n     * @return Matrix representing the element-wise square (^2) of m.\n     */\n    private static RealMatrix square(final RealMatrix m) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                d[r][c] = e * e;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix 1.\n     * @param n Input matrix 2.\n     * @return the matrix where the elements of m and n are element-wise multiplied.\n     */\n    private static RealMatrix times(final RealMatrix m, final RealMatrix n) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) * n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix 1.\n     * @param n Input matrix 2.\n     * @return Matrix where the elements of m and n are element-wise divided.\n     */\n    private static RealMatrix divide(final RealMatrix m, final RealMatrix n) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) / n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix.\n     * @param cols Columns to select.\n     * @return Matrix representing the selected columns.\n     */\n    private static RealMatrix selectColumns(final RealMatrix m, final int[] cols) {\n        double[][] d = new double[m.getRowDimension()][cols.length];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < cols.length; c++) {\n                d[r][c] = m.getEntry(r, cols[c]);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix.\n     * @param k Diagonal position.\n     * @return Upper triangular part of matrix.\n     */\n    private static RealMatrix triu(final RealMatrix m, int k) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = r <= c - k ? m.getEntry(r, c) : 0;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix.\n     * @return Row matrix representing the sums of the rows.\n     */\n    private static RealMatrix sumRows(final RealMatrix m) {\n        double[][] d = new double[1][m.getColumnDimension()];\n        for (int c = 0; c < m.getColumnDimension(); c++) {\n            double sum = 0;\n            for (int r = 0; r < m.getRowDimension(); r++) {\n                sum += m.getEntry(r, c);\n            }\n            d[0][c] = sum;\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix.\n     * @return the diagonal n-by-n matrix if m is a column matrix or the column\n     * matrix representing the diagonal if m is a n-by-n matrix.\n     */\n    private static RealMatrix diag(final RealMatrix m) {\n        if (m.getColumnDimension() == 1) {\n            double[][] d = new double[m.getRowDimension()][m.getRowDimension()];\n            for (int i = 0; i < m.getRowDimension(); i++) {\n                d[i][i] = m.getEntry(i, 0);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        } else {\n            double[][] d = new double[m.getRowDimension()][1];\n            for (int i = 0; i < m.getColumnDimension(); i++) {\n                d[i][0] = m.getEntry(i, i);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        }\n    }\n\n    /**\n     * Copies a column from m1 to m2.\n     *\n     * @param m1 Source matrix 1.\n     * @param col1 Source column.\n     * @param m2 Target matrix.\n     * @param col2 Target column.\n     */\n    private static void copyColumn(final RealMatrix m1, int col1, RealMatrix m2, int col2) {\n        for (int i = 0; i < m1.getRowDimension(); i++) {\n            m2.setEntry(i, col2, m1.getEntry(i, col1));\n        }\n    }\n\n    /**\n     * @param n Number of rows.\n     * @param m Number of columns.\n     * @return n-by-m matrix filled with 1.\n     */\n    private static RealMatrix ones(int n, int m) {\n        double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            Arrays.fill(d[r], 1.0);\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param n Number of rows.\n     * @param m Number of columns.\n     * @return n-by-m matrix of 0.0-values, diagonal has values 1.0.\n     */\n    private static RealMatrix eye(int n, int m) {\n        double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            if (r < m) {\n                d[r][r] = 1;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param n Number of rows.\n     * @param m Number of columns.\n     * @return n-by-m matrix of 0.0-values.\n     */\n    private static RealMatrix zeros(int n, int m) {\n        return new Array2DRowRealMatrix(n, m);\n    }\n\n    /**\n     * @param mat Input matrix.\n     * @param n Number of row replicates.\n     * @param m Number of column replicates.\n     * @return a matrix which replicates the input matrix in both directions.\n     */\n    private static RealMatrix repmat(final RealMatrix mat, int n, int m) {\n        int rd = mat.getRowDimension();\n        int cd = mat.getColumnDimension();\n        double[][] d = new double[n * rd][m * cd];\n        for (int r = 0; r < n * rd; r++) {\n            for (int c = 0; c < m * cd; c++) {\n                d[r][c] = mat.getEntry(r % rd, c % cd);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param start Start value.\n     * @param end End value.\n     * @param step Step size.\n     * @return a sequence as column matrix.\n     */\n    private static RealMatrix sequence(double start, double end, double step) {\n        int size = (int) ((end - start) / step + 1);\n        double[][] d = new double[size][1];\n        double value = start;\n        for (int r = 0; r < size; r++) {\n            d[r][0] = value;\n            value += step;\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    /**\n     * @param m Input matrix.\n     * @return the maximum of the matrix element values.\n     */\n    private static double max(final RealMatrix m) {\n        double max = -Double.MAX_VALUE;\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                if (max < e) {\n                    max = e;\n                }\n            }\n        }\n        return max;\n    }\n\n    /**\n     * @param m Input matrix.\n     * @return the minimum of the matrix element values.\n     */\n    private static double min(final RealMatrix m) {\n        double min = Double.MAX_VALUE;\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                if (min > e) {\n                    min = e;\n                }\n            }\n        }\n        return min;\n    }\n\n    /**\n     * @param m Input array.\n     * @return the maximum of the array values.\n     */\n    private static double max(final double[] m) {\n        double max = -Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (max < m[r]) {\n                max = m[r];\n            }\n        }\n        return max;\n    }\n\n    /**\n     * @param m Input array.\n     * @return the minimum of the array values.\n     */\n    private static double min(final double[] m) {\n        double min = Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (min > m[r]) {\n                min = m[r];\n            }\n        }\n        return min;\n    }\n\n    /**\n     * @param indices Input index array.\n     * @return the inverse of the mapping defined by indices.\n     */\n    private static int[] inverse(final int[] indices) {\n        int[] inverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            inverse[indices[i]] = i;\n        }\n        return inverse;\n    }\n\n    /**\n     * @param indices Input index array.\n     * @return the indices in inverse order (last is first).\n     */\n    private static int[] reverse(final int[] indices) {\n        int[] reverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            reverse[i] = indices[indices.length - i - 1];\n        }\n        return reverse;\n    }\n\n    /**\n     * @param size Length of random array.\n     * @return an array of Gaussian random numbers.\n     */\n    private double[] randn(int size) {\n        double[] randn = new double[size];\n        for (int i = 0; i < size; i++) {\n            randn[i] = random.nextGaussian();\n        }\n        return randn;\n    }\n\n    /**\n     * @param size Number of rows.\n     * @param popSize Population size.\n     * @return a 2-dimensional matrix of Gaussian random numbers.\n     */\n    private RealMatrix randn1(int size, int popSize) {\n        double[][] d = new double[size][popSize];\n        for (int r = 0; r < size; r++) {\n            for (int c = 0; c < popSize; c++) {\n                d[r][c] = random.nextGaussian();\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n}', 'tree': 'MethodDeclaration modifiers public_ter ^ ^ return_type BasicType name double_ter ^ ^ dimensions None_ter ^ ^ ^ ^ name meth0 ^ ^ parameters FormalParameter modifiers final_ter ^ ^ type BasicType name double_ter ^ ^ dimensions None_ter ^ ^ ^ ^ name par0 ^ ^ ^ ^ body ReturnStatement expression MethodInvocation arguments MemberReference member par0 ^ ^ ^ ^ member decode_ter ^ ^ ^ ^ ^ ^ ^ ', 'prob': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'mode': 0, 'line': 921, 'isa': False, 'fl_score': 1}]
before@0 batch0 x: 0: root ^  ; []
after@0 batch0 x: 0: root ^  ; []
copynode 0:  root modified ^ ^ ; ['root -> modified']
copynode 0:  root add ^ ^ ; ['root -> add']
copynode 0:  root ReturnStatement ^ ^ ; ['root -> ReturnStatement']
copynode 0:  root return_type ^ ^ ; ['root -> return_type']
copynode 0:  root member-member decode_ter ^ ^  ^ ^ ; ['copy-member']
copynode 0:  root parameters ^ ^ ; ['root -> parameters']
copynode 0:  root ^ ; ['root -> End']
copynode 0:  root StatementExpression ^ ^ ; ['root -> StatementExpression']
copynode 0:  root IfStatement ^ ^ ; ['root -> IfStatement']
copynode 0:  root par0 ^ ^ ; ['copy-FormalParameter']
before@1 batch0 x: -13.592551231384277: root par0 ^ ^  ; ['copy-FormalParameter']
after@1 batch0 x: -13.592551231384277: root par0 ^ ^  ; ['copy-FormalParameter']
copynode -0.18653449416160583:  root modified ^ member-member decode_ter ^ ^  ^ ^ ; ['root -> modified', 'copy-member']
copynode -0.18653449416160583:  root modified ^ ReturnStatement ^ ^ ; ['root -> modified', 'root -> ReturnStatement']
copynode -1.771802544593811:  root add ^ StatementExpression ^ ^ ; ['root -> add', 'root -> StatementExpression']
copynode -1.771802544593811:  root add ^ IfStatement ^ ^ ; ['root -> add', 'root -> IfStatement']
copynode -0.18653449416160583:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  ^ ^ ; ['root -> modified', 'copy-MemberReference']
copynode -1.771802544593811:  root add ^ ReturnStatement ^ ^ ; ['root -> add', 'root -> ReturnStatement']
copynode -1.771802544593811:  root add ^ ReturnStatement_ter ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter']
copynode -1.771802544593811:  root add ^ LocalVariableDeclaration ^ ^ ; ['root -> add', 'root -> LocalVariableDeclaration']
copynode -1.771802544593811:  root add ^ control ^ ^ ; ['root -> add', 'root -> control']
copynode -1.771802544593811:  root add ^ member-member decode_ter ^ ^  ^ ^ ; ['root -> add', 'copy-member']
copynode -0.18653449416160583:  root modified ^ StatementExpression ^ ^ ; ['root -> modified', 'root -> StatementExpression']
copynode -1.771802544593811:  root add ^ AssertStatement ^ ^ ; ['root -> add', 'root -> AssertStatement']
copynode -1.771802544593811:  root add ^ Statement_ter ^ ^ ; ['root -> add', 'root -> Statement_ter']
copynode -1.771802544593811:  root add ^ BreakStatement_ter ^ ^ ; ['root -> add', 'root -> BreakStatement_ter']
copynode -0.18653449416160583:  root modified ^ ReturnStatement_ter ^ ^ ; ['root -> modified', 'root -> ReturnStatement_ter']
copynode -10.4180908203125:  root ReturnStatement expression ^ ^ ^ ; ['root -> ReturnStatement', 'ReturnStatement -> expression']
copynode -0.18653449416160583:  root modified ^ member-member par0 ^ ^  ^ ^ ; ['root -> modified', 'copy-member']
copynode -10.85481071472168:  root return_type ReferenceType ^ ^ ^ ; ['root -> return_type', 'return_type -> ReferenceType']
copynode -11.298395156860352:  root parameters FormalParameter ^ ^ ^ ; ['root -> parameters', 'parameters -> FormalParameter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  unknown ^ ^ ^ ; ['copy-member', 'start -> unknown']
copynode -0.18653449416160583:  root modified ^ ^ ; ['root -> modified', 'root -> End']
copynode -11.847009658813477:  root StatementExpression expression ^ ^ ^ ; ['root -> StatementExpression', 'StatementExpression -> expression']
copynode -0.18653449416160583:  root modified ^ IfStatement ^ ^ ; ['root -> modified', 'root -> IfStatement']
copynode -12.096813201904297:  root IfStatement condition ^ ^ ^ ; ['root -> IfStatement', 'IfStatement -> condition']
copynode -10.85481071472168:  root return_type BasicType ^ ^ ^ ; ['root -> return_type', 'return_type -> BasicType']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  meth0 ^ ^ ^ ; ['copy-member', 'member -> meth0']
copynode -0.18653449416160583:  root modified ^ ContinueStatement_ter ^ ^ ; ['root -> modified', 'root -> ContinueStatement_ter']
copynode -0.18653449416160583:  root modified ^ BreakStatement_ter ^ ^ ; ['root -> modified', 'root -> BreakStatement_ter']
copynode -11.298395156860352:  root parameters ^ ^ ; ['root -> parameters', 'parameters -> End']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  add_ter ^ ^ ^ ; ['copy-member', 'member -> add_ter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  get_ter ^ ^ ^ ; ['copy-member', 'member -> get_ter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  debug_ter ^ ^ ^ ; ['copy-member', 'member -> debug_ter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  e_ter ^ ^ ^ ; ['copy-member', 'member -> e_ter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  max_ter ^ ^ ^ ; ['copy-member', 'member -> max_ter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  put_ter ^ ^ ^ ; ['copy-member', 'member -> put_ter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  size_ter ^ ^ ^ ; ['copy-member', 'member -> size_ter']
copynode -11.219039916992188:  root member-member decode_ter ^ ^  par0 ^ ^ ^ ; ['copy-member', 'member -> par0']
copynode -11.298395156860352:  root parameters MemberReference ^ ^ ^ ; ['root -> parameters', 'parameters -> MemberReference']
copynode -10.4180908203125:  root ReturnStatement expression MethodInvocation arguments MemberReference member par0 ^ ^ ^ ^ member decode_ter ^ ^ ^ ^ ^ ^ ; ['root -> ReturnStatement', 'copy-ReturnStatement']
copynode -11.298395156860352:  root parameters InferredFormalParameter ^ ^ ^ ; ['root -> parameters', 'parameters -> InferredFormalParameter']
copynode -10.85481071472168:  root return_type BasicType name double_ter ^ ^ dimensions None_ter ^ ^ ^ ^ ^ ; ['root -> return_type', 'copy-return_type']
copynode -11.298395156860352:  root parameters FormalParameter modifiers final_ter ^ ^ type BasicType name double_ter ^ ^ dimensions None_ter ^ ^ ^ ^ name par0 ^ ^ ^ ^ ^ ; ['root -> parameters', 'copy-parameters']
copynode -11.847009658813477:  root StatementExpression par0 ^ ^ ^ ; ['root -> StatementExpression', 'copy-FormalParameter']
copynode -10.4180908203125:  root ReturnStatement par0 ^ ^ ^ ; ['root -> ReturnStatement', 'copy-FormalParameter']
copynode -11.298395156860352:  root parameters Cast ^ ^ ^ ; ['root -> parameters', 'parameters -> Cast']
copynode -12.096813201904297:  root IfStatement par0 ^ ^ ^ ; ['root -> IfStatement', 'copy-FormalParameter']
copynode -10.85481071472168:  root return_type par0 ^ ^ ^ ; ['root -> return_type', 'copy-FormalParameter']
copynode -12.096813201904297:  root IfStatement condition ^ then_statement ^ ^ ^ ; ['root -> IfStatement', 'IfStatement -> condition then_statement']
copynode -11.847009658813477:  root StatementExpression unknown ^ ^ ^ ; ['root -> StatementExpression', 'start -> unknown']
copynode -10.85481071472168:  root return_type unknown ^ ^ ^ ; ['root -> return_type', 'start -> unknown']
copynode -10.4180908203125:  root ReturnStatement unknown ^ ^ ^ ; ['root -> ReturnStatement', 'start -> unknown']
copynode -12.096813201904297:  root IfStatement unknown ^ ^ ^ ; ['root -> IfStatement', 'start -> unknown']
copynode -11.298395156860352:  root parameters par0 ^ ^ ^ ; ['root -> parameters', 'copy-FormalParameter']
copynode -12.096813201904297:  root IfStatement condition ^ then_statement ^ else_statement ^ ^ ^ ; ['root -> IfStatement', 'IfStatement -> condition then_statement else_statement']
copynode -11.298395156860352:  root parameters unknown ^ ^ ^ ; ['root -> parameters', 'start -> unknown']
copynode -11.847009658813477:  root StatementExpression label ^ expression ^ ^ ^ ; ['root -> StatementExpression', 'StatementExpression -> label expression']
before@2 batch0 x: -30.94451141357422: root StatementExpression label ^ expression ^ ^ ^  ; ['root -> StatementExpression', 'StatementExpression -> label expression']
after@2 batch0 x: -30.94451141357422: root StatementExpression label ^ expression ^ ^ ^  ; ['root -> StatementExpression', 'StatementExpression -> label expression']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  unknown ^ ^ ^ ; ['root -> modified', 'copy-member', 'start -> unknown']
copynode -1.206786721944809:  root modified ^ ReturnStatement expression ^ ^ ^ ; ['root -> modified', 'root -> ReturnStatement', 'ReturnStatement -> expression']
copynode -2.2679994106292725:  root add ^ StatementExpression expression ^ ^ ^ ; ['root -> add', 'root -> StatementExpression', 'StatementExpression -> expression']
copynode -2.910154104232788:  root add ^ IfStatement condition ^ ^ ^ ; ['root -> add', 'root -> IfStatement', 'IfStatement -> condition']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  meth0 ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> meth0']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> member']
copynode -4.602122902870178:  root add ^ ReturnStatement expression ^ ^ ^ ; ['root -> add', 'root -> ReturnStatement', 'ReturnStatement -> expression']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  add_ter ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> add_ter']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  debug_ter ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> debug_ter']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  max_ter ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> max_ter']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  get_ter ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> get_ter']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  e_ter ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> e_ter']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  put_ter ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> put_ter']
copynode -7.376058220863342:  root add ^ ReturnStatement_ter ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter', 'root -> End']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  qualifier ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> qualifier member']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  par0 ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> par0']
copynode -0.6569356024265289:  root modified ^ member-member decode_ter ^ ^  i_ter ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> i_ter']
copynode -7.761804223060608:  root add ^ LocalVariableDeclaration type ^ declarators ^ ^ ^ ; ['root -> add', 'root -> LocalVariableDeclaration', 'LocalVariableDeclaration -> type declarators']
copynode -8.238876461982727:  root add ^ control EnhancedForControl ^ ^ ^ ; ['root -> add', 'root -> control', 'control -> EnhancedForControl']
copynode -8.664208978414536:  root modified ^ StatementExpression expression ^ ^ ^ ; ['root -> modified', 'root -> StatementExpression', 'StatementExpression -> expression']
copynode -7.761804223060608:  root add ^ LocalVariableDeclaration modifiers ^ type ^ declarators ^ ^ ^ ; ['root -> add', 'root -> LocalVariableDeclaration', 'LocalVariableDeclaration -> modifiers type declarators']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  unknown ^ ^ ^ ; ['root -> add', 'copy-member', 'start -> unknown']
copynode -8.794088006019592:  root add ^ AssertStatement condition ^ ^ ^ ; ['root -> add', 'root -> AssertStatement', 'AssertStatement -> condition']
copynode -9.06687319278717:  root add ^ Statement_ter ^ ^ ; ['root -> add', 'root -> Statement_ter', 'root -> End']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  postfix_operators ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> postfix_operators member']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  prefix_operators ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> prefix_operators member']
copynode -9.540332436561584:  root add ^ BreakStatement_ter ^ ^ ; ['root -> add', 'root -> BreakStatement_ter', 'root -> End']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  selectors ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> selectors member']
copynode -1.206786721944809:  root modified ^ ReturnStatement expression MethodInvocation arguments MemberReference member par0 ^ ^ ^ ^ member decode_ter ^ ^ ^ ^ ^ ^ ; ['root -> modified', 'root -> ReturnStatement', 'copy-ReturnStatement']
copynode -10.180375665426254:  root modified ^ ReturnStatement_ter ^ ReturnStatement ^ ^ ; ['root -> modified', 'root -> ReturnStatement_ter', 'root -> ReturnStatement']
copynode -10.642169564962387:  root modified ^ member-member par0 ^ ^  unknown ^ ^ ^ ; ['root -> modified', 'copy-member', 'start -> unknown']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  meth0 ^ ^ ^ ; ['root -> add', 'copy-member', 'member -> meth0']
copynode -8.238876461982727:  root add ^ control ForControl ^ ^ ^ ; ['root -> add', 'root -> control', 'control -> ForControl']
copynode -10.419055808102712:  root ReturnStatement expression MethodInvocation ^ ^ ^ ^ ; ['root -> ReturnStatement', 'ReturnStatement -> expression', 'expression -> MethodInvocation']
copynode -7.376058220863342:  root add ^ ReturnStatement_ter ^ StatementExpression ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter', 'root -> StatementExpression']
copynode -7.376058220863342:  root add ^ ReturnStatement_ter ^ IfStatement ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter', 'root -> IfStatement']
copynode -7.761804223060608:  root add ^ LocalVariableDeclaration annotations ^ type ^ declarators ^ ^ ^ ; ['root -> add', 'root -> LocalVariableDeclaration', 'LocalVariableDeclaration -> annotations type declarators']
copynode -11.32747227884829:  root parameters FormalParameter modifiers ^ type ^ name ^ ^ ^ ^ ; ['root -> parameters', 'parameters -> FormalParameter', 'FormalParameter -> modifiers type name']
copynode -11.964252084493637:  root modified ^ IfStatement condition ^ ^ ^ ; ['root -> modified', 'root -> IfStatement', 'IfStatement -> condition']
copynode -11.849184551741928:  root StatementExpression expression MethodInvocation ^ ^ ^ ^ ; ['root -> StatementExpression', 'StatementExpression -> expression', 'expression -> MethodInvocation']
copynode -11.211369216442108:  root return_type ReferenceType name ^ arguments ^ ^ ^ ^ ; ['root -> return_type', 'return_type -> ReferenceType', 'ReferenceType -> name arguments']
copynode -4.602122902870178:  root add ^ ReturnStatement expression MethodInvocation arguments MemberReference member par0 ^ ^ ^ ^ member decode_ter ^ ^ ^ ^ ^ ^ ; ['root -> add', 'root -> ReturnStatement', 'copy-ReturnStatement']
copynode -10.180375665426254:  root modified ^ ReturnStatement_ter ^ ^ ; ['root -> modified', 'root -> ReturnStatement_ter', 'root -> End']
copynode -10.419055808102712:  root ReturnStatement expression MemberReference ^ ^ ^ ^ ; ['root -> ReturnStatement', 'ReturnStatement -> expression', 'expression -> MemberReference']
copynode -11.474692672491074:  root member-member decode_ter ^ ^  unknown ^ ^ ^ ; ['copy-member', 'start -> unknown', 'root -> End']
copynode -10.419055808102712:  root ReturnStatement expression Literal ^ ^ ^ ^ ; ['root -> ReturnStatement', 'ReturnStatement -> expression', 'expression -> Literal']
copynode -10.419055808102712:  root ReturnStatement expression BinaryOperation ^ ^ ^ ^ ; ['root -> ReturnStatement', 'ReturnStatement -> expression', 'expression -> BinaryOperation']
copynode -12.485571503639221:  root return_type BasicType name ^ ^ ^ ^ ; ['root -> return_type', 'return_type -> BasicType', 'BasicType -> name']
copynode -9.06687319278717:  root add ^ Statement_ter ^ StatementExpression ^ ^ ; ['root -> add', 'root -> Statement_ter', 'root -> StatementExpression']
copynode -11.474692672491074:  root member-member decode_ter ^ ^  unknown ^ ^ StatementExpression ^ ^ ; ['copy-member', 'start -> unknown', 'root -> StatementExpression']
copynode -10.642169564962387:  root modified ^ member-member par0 ^ ^  meth0 ^ ^ ^ ; ['root -> modified', 'copy-member', 'member -> meth0']
copynode -2.2679994106292725:  root add ^ StatementExpression par0 ^ ^ ^ ; ['root -> add', 'root -> StatementExpression', 'copy-FormalParameter']
copynode -12.097068819275592:  root IfStatement condition BinaryOperation ^ ^ ^ ^ ; ['root -> IfStatement', 'IfStatement -> condition', 'condition -> BinaryOperation']
copynode -10.180375665426254:  root modified ^ ReturnStatement_ter ^ StatementExpression ^ ^ ; ['root -> modified', 'root -> ReturnStatement_ter', 'root -> StatementExpression']
copynode -11.32747227884829:  root parameters FormalParameter type ^ name ^ ^ ^ ^ ; ['root -> parameters', 'parameters -> FormalParameter', 'FormalParameter -> type name']
copynode -11.211369216442108:  root return_type ReferenceType name ^ ^ ^ ^ ; ['root -> return_type', 'return_type -> ReferenceType', 'ReferenceType -> name']
copynode -9.540332436561584:  root add ^ BreakStatement_ter ^ StatementExpression ^ ^ ; ['root -> add', 'root -> BreakStatement_ter', 'root -> StatementExpression']
copynode -9.06687319278717:  root add ^ Statement_ter ^ IfStatement ^ ^ ; ['root -> add', 'root -> Statement_ter', 'root -> IfStatement']
copynode -12.980996698141098:  root modified ^ ContinueStatement_ter ^ ^ ; ['root -> modified', 'root -> ContinueStatement_ter', 'root -> End']
copynode -10.180375665426254:  root modified ^ ReturnStatement_ter ^ member-member decode_ter ^ ^  ^ ^ ; ['root -> modified', 'root -> ReturnStatement_ter', 'copy-member']
copynode -12.097068819275592:  root IfStatement condition MethodInvocation ^ ^ ^ ^ ; ['root -> IfStatement', 'IfStatement -> condition', 'condition -> MethodInvocation']
copynode -11.474692672491074:  root member-member decode_ter ^ ^  unknown ^ ^ ReturnStatement ^ ^ ; ['copy-member', 'start -> unknown', 'root -> ReturnStatement']
copynode -13.203576654195786:  root modified ^ BreakStatement_ter ^ ReturnStatement ^ ^ ; ['root -> modified', 'root -> BreakStatement_ter', 'root -> ReturnStatement']
copynode -7.376058220863342:  root add ^ ReturnStatement_ter ^ ReturnStatement ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter', 'root -> ReturnStatement']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  qualifier ^ selectors ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> qualifier selectors member']
copynode -9.540332436561584:  root add ^ BreakStatement_ter ^ IfStatement ^ ^ ; ['root -> add', 'root -> BreakStatement_ter', 'root -> IfStatement']
copynode -12.875300645828247:  root member-member decode_ter ^ ^  meth0 ^ ^ StatementExpression ^ ^ ; ['copy-member', 'member -> meth0', 'root -> StatementExpression']
copynode -10.419055808102712:  root ReturnStatement expression This ^ ^ ^ ^ ; ['root -> ReturnStatement', 'ReturnStatement -> expression', 'expression -> This']
copynode -1.206786721944809:  root modified ^ ReturnStatement par0 ^ ^ ^ ; ['root -> modified', 'root -> ReturnStatement', 'copy-FormalParameter']
copynode -10.419055808102712:  root ReturnStatement expression TernaryExpression ^ ^ ^ ^ ; ['root -> ReturnStatement', 'ReturnStatement -> expression', 'expression -> TernaryExpression']
copynode -12.097068819275592:  root IfStatement condition MemberReference ^ ^ ^ ^ ; ['root -> IfStatement', 'IfStatement -> condition', 'condition -> MemberReference']
copynode -11.474692672491074:  root member-member decode_ter ^ ^  unknown ^ ^ IfStatement ^ ^ ; ['copy-member', 'start -> unknown', 'root -> IfStatement']
copynode -10.180375665426254:  root modified ^ ReturnStatement_ter ^ ReturnStatement_ter ^ ^ ; ['root -> modified', 'root -> ReturnStatement_ter', 'root -> ReturnStatement_ter']
copynode -11.849184551741928:  root StatementExpression expression Assignment ^ ^ ^ ^ ; ['root -> StatementExpression', 'StatementExpression -> expression', 'expression -> Assignment']
copynode -12.875300645828247:  root member-member decode_ter ^ ^  meth0 ^ ^ ^ ; ['copy-member', 'member -> meth0', 'root -> End']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  add_ter ^ ^ ^ ; ['root -> add', 'copy-member', 'member -> add_ter']
copynode -11.211369216442108:  root return_type ReferenceType name ^ dimensions ^ ^ ^ ^ ; ['root -> return_type', 'return_type -> ReferenceType', 'ReferenceType -> name dimensions']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  prefix_operators ^ qualifier ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> prefix_operators qualifier member']
copynode -11.211369216442108:  root return_type ReferenceType name ^ dimensions ^ arguments ^ ^ ^ ^ ; ['root -> return_type', 'return_type -> ReferenceType', 'ReferenceType -> name dimensions arguments']
copynode -11.211369216442108:  root return_type ReferenceType name ^ arguments ^ sub_type ^ ^ ^ ^ ; ['root -> return_type', 'return_type -> ReferenceType', 'ReferenceType -> name arguments sub_type']
copynode -7.376058220863342:  root add ^ ReturnStatement_ter ^ ReturnStatement_ter ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter', 'root -> ReturnStatement_ter']
copynode -9.06687319278717:  root add ^ Statement_ter ^ ReturnStatement ^ ^ ; ['root -> add', 'root -> Statement_ter', 'root -> ReturnStatement']
copynode -8.238876461982727:  root add ^ control ForControl_ter ^ ^ ^ ; ['root -> add', 'root -> control', 'control -> ForControl_ter']
copynode -7.376058220863342:  root add ^ ReturnStatement_ter ^ BreakStatement_ter ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter', 'root -> BreakStatement_ter']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  get_ter ^ ^ ^ ; ['root -> add', 'copy-member', 'member -> get_ter']
copynode -7.761804223060608:  root add ^ LocalVariableDeclaration modifiers ^ annotations ^ type ^ declarators ^ ^ ^ ; ['root -> add', 'root -> LocalVariableDeclaration', 'LocalVariableDeclaration -> modifiers annotations type declarators']
copynode -7.376058220863342:  root add ^ ReturnStatement_ter ^ ContinueStatement_ter ^ ^ ; ['root -> add', 'root -> ReturnStatement_ter', 'root -> ContinueStatement_ter']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  debug_ter ^ ^ ^ ; ['root -> add', 'copy-member', 'member -> debug_ter']
copynode -12.875300645828247:  root member-member decode_ter ^ ^  meth0 ^ ^ IfStatement ^ ^ ; ['copy-member', 'member -> meth0', 'root -> IfStatement']
copynode -12.875300645828247:  root member-member decode_ter ^ ^  meth0 ^ ^ ReturnStatement ^ ^ ; ['copy-member', 'member -> meth0', 'root -> ReturnStatement']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  par0 ^ ^ ^ ; ['root -> add', 'copy-member', 'member -> par0']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  postfix_operators ^ selectors ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> postfix_operators selectors member']
copynode -4.433174222707748:  root modified ^ MemberReference-MemberReference member par0 ^ ^ ^  prefix_operators ^ selectors ^ member ^ ^ ^ ; ['root -> modified', 'copy-MemberReference', 'MemberReference -> prefix_operators selectors member']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  e_ter ^ ^ ^ ; ['root -> add', 'copy-member', 'member -> e_ter']
copynode -9.540332436561584:  root add ^ BreakStatement_ter ^ ReturnStatement ^ ^ ; ['root -> add', 'root -> BreakStatement_ter', 'root -> ReturnStatement']
copynode -11.211369216442108:  root return_type ReferenceType par0 ^ ^ ^ ^ ; ['root -> return_type', 'return_type -> ReferenceType', 'copy-FormalParameter']
copynode -8.637253403663635:  root add ^ member-member decode_ter ^ ^  max_ter ^ ^ ^ ; ['root -> add', 'copy-member', 'member -> max_ter']
before@3 batch0 x: -15.244225144386292: root add ^ member-member decode_ter ^ ^  max_ter ^ ^ ^  ; ['root -> add', 'copy-member', 'member -> max_ter']
stderr: Check out program version: Math-20b........................................ OK
OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=1G; support was removed in 8.0
Running ant (export.dir.src.classes)....................................... OK

  0%|          | 0/1 [00:00<?, ?it/s]/root/projects/Recoder-bwk/run.py:527: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tmpdepth = np.array(tmpdepth)
/root/envs/recoder/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
  0%|          | 0/1 [00:04<?, ?it/s]
Traceback (most recent call last):
  File "testDefect4j.py", line 638, in <module>
    ans = solveone(data, model)
  File "/root/projects/Recoder-bwk/run.py", line 1100, in solveone
    ans = BeamSearch((x[0], x[1], None, None, None, None, None, None, x[2], x[3]), dev_set, model, 100, args.batch_size, indexs)
  File "/root/projects/Recoder-bwk/run.py", line 541, in BeamSearch
    result = model(gVar(tmpnl), gVar(tmpnlad), gVar(tmprule), gVar(tmpruleparent), gVar(tmprulechild), gVar(tmpAd), gVar(tmptreepath), gVar(tmpnl8), gVar(tmpnl9), tmpf, tmpc, tmpindex, tmpchar, tmpindex2, rulead, antimasks, None, "test")
  File "/root/envs/recoder/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/root/projects/Recoder-bwk/Model.py", line 172, in forward
    genP1, _ = self.copy2(rulenoter.unsqueeze(0), decode)
  File "/root/envs/recoder/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/root/projects/Recoder-bwk/Model.py", line 79, in forward
    genP = self.LinearRes(F.tanh(sourceLinear.unsqueeze(1) + targetLinear.unsqueeze(2))).squeeze(-1)
  File "/root/envs/recoder/lib/python3.7/site-packages/torch/nn/functional.py", line 1341, in tanh
    return input.tanh()
RuntimeError: CUDA out of memory. Tried to allocate 1.97 GiB (GPU 0; 23.65 GiB total capacity; 2.85 GiB already allocated; 1.51 GiB free; 1.60 GiB cached)
